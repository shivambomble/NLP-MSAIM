{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shivam Bomble\n",
    "3MSAIM 2448510 NLP Lab 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('punkt')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(doc1, doc2):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([doc1, doc2])\n",
    "    return cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_sim(doc1, doc2):\n",
    "    set1, set2 = set(preprocess_text(doc1)), set(preprocess_text(doc2))\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_sim(doc1, doc2):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform([doc1, doc2])\n",
    "    return euclidean_distances(tfidf_matrix[0], tfidf_matrix[1])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.1844\n",
      "Jaccard Similarity: 0.1111\n",
      "Euclidean Distance: 1.2772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Sample documents\n",
    "doc1 = \"Artificial intelligence is transforming industries worldwide.\"\n",
    "doc2 = \"AI is revolutionizing global industries with automation.\"\n",
    "\n",
    "cos_sim = cosine_sim(doc1, doc2)\n",
    "jac_sim = jaccard_sim(doc1, doc2)\n",
    "euc_sim = euclidean_sim(doc1, doc2)\n",
    "\n",
    "print(f\"Cosine Similarity: {cos_sim:.4f}\")\n",
    "print(f\"Jaccard Similarity: {jac_sim:.4f}\")\n",
    "print(f\"Euclidean Distance: {euc_sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cosine Similarity is more effective for longer documents with meaningful term frequency variations.\n",
    "2. Jaccard Similarity is best when exact word overlap matters.\n",
    "3. Euclidean Distance is useful for measuring absolute differences, but it can be sensitive to document length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    subjectivity = blob.sentiment.subjectivity\n",
    "    return polarity, subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment_vader(text):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    polarity = scores['compound']\n",
    "    subjectivity = (scores['pos'] + scores['neg']) / 2  # Approximation\n",
    "    return polarity, subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity1, subjectivity1 = analyze_sentiment(doc1)\n",
    "polarity2, subjectivity2 = analyze_sentiment(doc2)\n",
    "\n",
    "polarity1_vader, subjectivity1_vader = analyze_sentiment_vader(doc1)\n",
    "polarity2_vader, subjectivity2_vader = analyze_sentiment_vader(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 - Polarity: -0.6000, Subjectivity: 1.0000\n",
      "Document 2 - Polarity: 0.0000, Subjectivity: 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Document 1 - Polarity: {polarity1:.4f}, Subjectivity: {subjectivity1:.4f}\")\n",
    "print(f\"Document 2 - Polarity: {polarity2:.4f}, Subjectivity: {subjectivity2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 - VADER Polarity: 0.4767, Subjectivity: 0.1915\n",
      "Document 2 - VADER Polarity: 0.0000, Subjectivity: 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Document 1 - VADER Polarity: {polarity1_vader:.4f}, Subjectivity: {subjectivity1_vader:.4f}\")\n",
    "print(f\"Document 2 - VADER Polarity: {polarity2_vader:.4f}, Subjectivity: {subjectivity2_vader:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **VADER vs TextBlob (Short Comparison)**\n",
    "\n",
    "| Feature         | **VADER** | **TextBlob** |\n",
    "|---------------|----------|-------------|\n",
    "| **Approach** | Lexicon & rule-based | Statistical & ML-based |\n",
    "| **Best for** | Short, social media texts (e.g., tweets) | General text, long documents |\n",
    "| **Polarity Range** | -1 (negative) to +1 (positive) | -1 (negative) to +1 (positive) |\n",
    "| **Subjectivity** | Not directly available (approximated) | 0 (objective) to 1 (subjective) |\n",
    "| **Handles Emojis & Slang?** | Yes | No |\n",
    "| **Context Awareness** | Limited, but considers intensifiers (e.g., \"very good\") | Less context-aware, relies on word-level analysis |\n",
    "| **Speed** | Faster | Slower |\n",
    "\n",
    "### **Which One to Use?**\n",
    "- **Use VADER** for short, informal texts (tweets, reviews, chat messages).\n",
    "- **Use TextBlob** for formal documents, news articles, or general sentiment analysis.\n",
    "\n",
    "Since you're analyzing documents, **TextBlob is generally better**, but **VADER** can be useful if documents contain conversational or social media-style text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes Accuracy: 0.9399343031440638\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      5962\n",
      "           1       1.00      0.11      0.20       431\n",
      "\n",
      "    accuracy                           0.94      6393\n",
      "   macro avg       0.97      0.55      0.58      6393\n",
      "weighted avg       0.94      0.94      0.92      6393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Sentiment Analysis with Naïve Bayes ---\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/dD2405/Twitter_Sentiment_Analysis/master/train.csv')\n",
    "data = data[['tweet', 'label']]\n",
    "data = data.sample(frac=1).reset_index(drop=True)  # Shuffle the dataset to make it more complex\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['tweet'], data['label'], test_size=0.2, random_state=42)\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Naïve Bayes Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It loads a dataset containing tweets and their sentiment labels (0 = negative, 1 = positive).\n",
    "The dataset is filtered to keep only the tweet text and label.\n",
    "\n",
    "High accuracy (93.9%) suggests the model performs well overall.\n",
    "Class imbalance problem:\n",
    "Negative tweets (label 0) are well classified (94% precision, 100% recall).\n",
    "Positive tweets (label 1) have poor recall (only 11%), meaning most positive tweets are misclassified.\n",
    "\n",
    "The dataset is imbalanced (more negative tweets than positive ones)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "400/400 [==============================] - 59s 141ms/step - loss: 0.2622 - accuracy: 0.9166 - val_loss: 0.1919 - val_accuracy: 0.9374\n",
      "Epoch 2/10\n",
      "400/400 [==============================] - 58s 144ms/step - loss: 0.1234 - accuracy: 0.9559 - val_loss: 0.1423 - val_accuracy: 0.9534\n",
      "Epoch 3/10\n",
      "400/400 [==============================] - 66s 165ms/step - loss: 0.0585 - accuracy: 0.9788 - val_loss: 0.1507 - val_accuracy: 0.9539\n",
      "Epoch 4/10\n",
      "400/400 [==============================] - 72s 179ms/step - loss: 0.0294 - accuracy: 0.9904 - val_loss: 0.1629 - val_accuracy: 0.9570\n",
      "Epoch 5/10\n",
      "400/400 [==============================] - 69s 172ms/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.1865 - val_accuracy: 0.9532\n",
      "Epoch 6/10\n",
      "400/400 [==============================] - 87s 217ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.2078 - val_accuracy: 0.9570\n",
      "Epoch 7/10\n",
      "400/400 [==============================] - 68s 169ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.2088 - val_accuracy: 0.9460\n",
      "Epoch 8/10\n",
      "400/400 [==============================] - 61s 152ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.2460 - val_accuracy: 0.9503\n",
      "Epoch 9/10\n",
      "400/400 [==============================] - 63s 158ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.2772 - val_accuracy: 0.9515\n",
      "Epoch 10/10\n",
      "400/400 [==============================] - 51s 128ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.2844 - val_accuracy: 0.9556\n",
      "200/200 [==============================] - 3s 17ms/step - loss: 0.2844 - accuracy: 0.9556\n",
      "RNN Model Evaluation: [0.2844448983669281, 0.9555764198303223]\n"
     ]
    }
   ],
   "source": [
    "# --- Sentiment Analysis Using RNN ---\n",
    "tokenizer = Tokenizer(num_words=20000)  # Increase vocabulary size for complexity\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=150)\n",
    "X_test_seq = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=150)\n",
    "\n",
    "y_train, y_test = np.array(y_train), np.array(y_test)\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=20000, output_dim=128, input_length=150),  # Larger embedding dimension\n",
    "    SimpleRNN(128, return_sequences=False),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_seq, y_train, epochs=10, batch_size=64, validation_data=(X_test_seq, y_test))  # More epochs and batch size\n",
    "print(\"RNN Model Evaluation:\", model.evaluate(X_test_seq, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN Model:\n",
    "Embedding layer (128-dimensional word representations).\n",
    "SimpleRNN layer (128 units).\n",
    "Dense output layer (Sigmoid activation for binary classification).\n",
    "Training: Runs for 10 epochs, with batch size 64.\n",
    "Evaluation: Computes loss and accuracy.\n",
    "Example Output:\n",
    "\n",
    "Training accuracy: 99.9%\n",
    "Validation accuracy: 95.1%\n",
    "Model generalizes well but may be overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
